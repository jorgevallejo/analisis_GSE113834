---
title: "Análisis GSE113834"
subtitle: "Análisis Datos Ómicos - PEC 1"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
      toc: true
      #pandoc_args: -V toc-title="Sumario"
# Next code for knitting both types of documents automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all",
  output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE)

# This is a try:
knitr::opts_knit$set(stop_on_error = 2L)
# See ?evaluate::evaluate
# What I am trying to do is to make knitr stop
# when an error is found instead of running the
# complete script.
```

```{r estructura de directorios}
# Directory for raw data
if (!(dir.exists("data"))){
dir.create("data")
}
# Directory for results
if (!(dir.exists("results"))){
  dir.create("results")
}
# Directory for processed data
if (!(dir.exists("intermediateResults"))){
  dir.create("intermediateResults")
}
```

```{r prepare data, eval=FALSE}
GSE_address <- "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE113834"
data_origin <- "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE113834&format=file"

# De-compress files
cel_tar <- "data/GSE113834_RAW.tar"
untar(cel_tar, exdir = "data")
file.remove(cel_tar)
zip_files <- dir("data")
sapply(zip_files, function(x){
  system2("gunzip",
          args = c("-d", paste0("data/", x)))
  })

# Generate targets file
# initial_target_file.csv is a copy-paste of the samples/group table
# from the GSE webpage to LibreOffice Calc and saved as a csv file.
targets <- read.csv2("data/initial_target_file.csv", header = FALSE, stringsAsFactors = FALSE)
# Remove trailing spaces in sample names
targets$V1 <- sub("[[:blank:]]", "", targets$V1)
# Add Condition column
targets$Condicion <- as.factor(sub("-[[:print:]]+", "", targets[,2]))
# Add Material column
targets$Material <- as.factor(sub("[[:graph:]]+[[:blank:]]", "", targets[,2]))
# Add Group column
targets$Grupo <- as.factor(paste(targets$Condicion, targets$Material, sep="-"))
# Rearrange columns
targets <- targets[, c(1, 5, 3, 4, 2)]
# Change column names
colnames(targets)[c(1, 5)] <- c("Archivo", "Abreviado")
# Write final targets file
write.csv2(targets, file = "intermediateResults/targets2.csv", row.names = FALSE)
```


```{r delete results files, eval= FALSE}
# Run this chunk ONLY if you want to re-do
# all the report FROM ZERO.
# Remember that the .RData files are there to
# avoid unnecesarily redoing long data processing.

file.remove(c("./intermediateResults/dist_matrix.RData",
              "./intermediateResults/gse.RData",
              "./intermediateResults/Pset.RData",
              "./intermediateResults/targets2.csv"))


```


```{r libraries, include=FALSE}
# Install packages
# Load packages
# ...

library(knitr)

```

Grupos experimentales (columna grupos)
Condición del sujeto (condición)
Material usado (material)
Número total de muestras:


```{r construct targets file, eval=FALSE}
# Read the CEL files
library('oligo')
celFiles <- list.celfiles("data", full.names=TRUE)
# Generate phenoData
library(Biobase)
my.targets <- read.AnnotatedDataFrame(file.path("intermediateResults", "targets2.csv"), header = TRUE, row.names=1, sep = ";")
```

```{r Expression Set with read.celfiles, eval=FALSE}
# Construct the ExpressionSet object
library(primeviewprobe)
library(oligoClasses)
rawData <- read.celfiles(celFiles, phenoData = my.targets, pkgname="primeviewcdf")
```

```{r construct ExpressionSet with GEOquery, eval=FALSE}
library(GEOquery)
GEOfile <- "intermediateResults/gse.RData"
if(file.exists(GEOfile)){
  load(GEOfile)
}else{
gse <- getGEO("data/GSE113834_series_matrix.txt.gz", GSEMatrix = TRUE, destdir="data", getGPL = TRUE)
# The value is a list of ExpressionSet objects
# (each GSM is one of those ExpressionSet objects)
save("gse", file="intermediateResults/gse.RData")
}
gse_expr <- unlist(gse[[1]])
```
Probemos otro método para construir el objeto ExpressionSet:
```{r ExpressionSet con affy}
library(affy)
rawData <- read.affybatch(filenames = celFiles,
                          phenoData = my.targets)
```



# Control de calidad de los datos en bruto
Con el control de calidad pretendemos averiguar si los datos en bruto tienen calidad suficiente para continuar con el análisis, antes de normalizarlos.

En esta ocasión usaremos el paquete de análisis ArrayQualityMetrics.

```{r control de calidad con ArrayQualityMetrics, eval=FALSE}
library(arrayQualityMetrics)
arrayQualityMetrics(rawData)
```

```{r re-used variables}
array_labels <- noquote(pData(rawData)$X.Abreviado.)
graph_colours <- rainbow(length(array_labels))
```


## Gráficos de densidad

Los gráficos de densidad nos informan acerca de la forma y posición de las señales sin normalizar.

```{r grafico de densidad}
hist(rawData, col = graph_colours,
     main="Densidad de la señal en bruto",
     ylab="Densidad", xlab= "log Intensidad")

legend(x=11.9, y=0.31, legend=array_labels, 
       fill=graph_colours, ncol=2, bty="n", cex=0.5)
```

Este caso vemos que la curva de densidad es similar en todas las muestras, sin mostrar grandes diferencias.

## Diagrama de cajas

El gráfico de diagrama de cajas nos permite comparar la distribución de la intensidad entre las diferentes muestras.

```{r boxplot}
boxplot(rawData,
        names=array_labels,
        cex.axis=0.5, las=2, which="both",
        col = graph_colours,
        main="Distribución de valores de intensidad en bruto")
```

Podemos ver que ninguna de las muestras destaca entre el resto. Hay pequeñas variaciones, pero es una característica esperable cuando comparamos los datos de intensidad en bruto.

## Dendrograma del clúster jerárquico

El dendrograma nos ayuda a representar cómo se agrupan las muestras, y da pistas acerca de cuál es el factor experimental que determina las diferencias entre muestras. Aquellas muestras con datos más similares aparecerán agrupadas.

```{r dendrograma, fig.height=5, fig.width=8}
# Calcular matriz de distancias
if(file.exists("intermediateResults/dist_matrix.RData")){
  load("intermediateResults/dist_matrix.RData")
  }else{
    dist_matrix <- dist(t(exprs(rawData)))
    save(dist_matrix, file = "intermediateResults/dist_matrix.RData")
  }
# Cambia el atributo 'Labels' con los nombres abreviados de las muestras.
attr(dist_matrix, "Labels")<- array_labels

hier_clust <- hclust(dist_matrix, "average")

plot(hier_clust, main="Dendrograma de datos muestrales en bruto",
     hang = -1, cex = 0.66, xlab= "Muestras", sub="", ylab = "", yaxt="n")
```

En este caso y a primera vista no parece haber un factor claro que haga que unas muestras están más cercanas entre sí que otras. Quizá el material (input/wash/eluted) en primer lugar, y el grupo (ctrl/asd) en segundo lugar; pero no es definitivo.

## Componentes principales

El análisis de componentes principales nos puede servir para detectar si las muestras se agrupan con otras muestras procedentes del mismo grupo o si no hay correspondencia entre muestras del mismo grupo.

```{r funcion plotPCA3}

# Función para visualización de componentes principales
# Código adaptado de Statistical Analysis of Microarray data (adapted for teaching purposes) Based on Gonzalo, Ricardo and Sanchez-Pla, Alex (2019)

 library(ggplot2)
 library(ggrepel)
 plotPCA3 <- function (datos, labels, factor, title, scale,colores, size = 1.5, glineas = 0.25) {
   data <- prcomp(t(datos),scale=scale)
   # plot adjustments
   dataDf <- data.frame(data$x)
   Group <- factor
   loads <- round(data$sdev^2/sum(data$sdev^2)*100,1)
   # main plot
   p1 <- ggplot(dataDf,aes(x=PC1, y=PC2)) +
     theme_classic() +
     geom_hline(yintercept = 0, color = "gray70") +
     geom_vline(xintercept = 0, color = "gray70") +
     geom_point(aes(color = Group), alpha = 0.55, size = 3) +
     coord_cartesian(xlim = c(min(data$x[,1])-5,max(data$x[,1])+5)) +
     scale_fill_discrete(name = "Grupo")
   # avoiding labels superposition
   p1 + geom_text_repel(aes(y = PC2 + 0.25, label = labels),segment.size = 0.25, size = size) + 
     labs(x = c(paste("PC1",loads[1],"%")),y=c(paste("PC2",loads[2],"%"))) +  
     ggtitle(paste("Análisis de componentes principales para: ",title,sep=" "))+ 
     theme(plot.title = element_text(hjust = 0.5)) +
     scale_color_manual(values=colores)
 }
```

```{r componentes ppales}
plotPCA3(exprs(rawData), labels = array_labels,
         factor = pData(rawData)$X.Grupo, title="Datos brutos",
         scale = FALSE, size = 3, colores = rainbow(6))
```

De forma similar a lo que veíamos en el dendrograma, las diferencias más importantes entre las muestras parecen deberse al material antes que al grupo.

La componente más importante explica el 67.7% de la variabilidad total de las muestras, y parece deberse principalmente al material; las muestras "wash" se agrupan más a la izquierda, compartiendo la zona central con las muestras "input", y las muestras "eluted" agrupadas hacia la derecha del gráfico.

La muestra "CTRL-1 INPUT" aparece alejada, no sólo de las otras muestras del grupo CTRL-INPUT, sino de todo el resto de muestras. Esto por sí sólo no significa que la muestra sea defectuosa, pero sí que deberíamos fijarnos en ella y comprobar qué resultados obtiene en el resto de gráficos.

## Imagen del array

Examinar la imagen del array nos permite hacer una evaluación de calidad a nivel "macro". Nos permite hacer una estimación a ojo de características como del balance del color, la uniformidad en la hibridación y en los spots, de si el background es mayor de lo normal y de la existencia de artefactos como el polvo o pequeñas marcas (rasguños).


```{r array image, fig.height=32, fig.width=12}
#pseudo image of the weights for the first arrays in the dataset
par(mfrow=c(9,3))
for (num in 1:length(array_labels)){
  image(rawData[, num], main = array_labels[num])
}
```

Todas las imágenes tienen una estructura en el centro que no he sabido averiguar si corresponde a los datos originales o si la he introducido y inadvertidamente mientras manipulaba los datos.

A simple vista no se observa ningún gran defecto como roturas, burbujas o manchas. Si que parece a simple vista que las imágenes de material "INPUT" son más oscuras que el resto.

# Normalización de los datos

Antes de empezar el análisis de expresión es necesario procesar los datos brutos de forma que los datos de las diferentes muestras (micorarrays) sean comparables. El proceso de normalización intenta asegurarse de que las diferencias de intensidad reflejen la expresión diferencial de los genes, eliminando sesgos producidos por razones técnicas.



# Apéndice A: Reproducibilidad
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
sessionInfo() # For better reproducibility
```








