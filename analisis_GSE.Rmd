---
title: "Análisis GSE113834"
subtitle: "Análisis Datos Ómicos - PEC 1"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
      toc: true
      #pandoc_args: -V toc-title="Sumario"
# Next code for knitting both types of documents automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all",
  output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE)

# This is a try:
knitr::opts_knit$set(stop_on_error = 2L)
# See ?evaluate::evaluate
# What I am trying to do is to make knitr stop
# when an error is found instead of running the
# complete script.
```

```{r estructura de directorios}
# Directory for raw data
if (!(dir.exists("data"))){
dir.create("data")
}
# Directory for results
if (!(dir.exists("results"))){
  dir.create("results")
}
# Directory for processed data
if (!(dir.exists("intermediateResults"))){
  dir.create("intermediateResults")
}
```

```{r prepare data, eval=FALSE}
GSE_address <- "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE113834"
data_origin <- "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE113834"

# De-compress files
cel_tar <- "data/GSE113834_RAW.tar"
untar(cel_tar, exdir = "data")
file.remove(cel_tar)
zip_files <- dir("data")
sapply(zip_files, function(x){
  system2("gunzip",
          args = c("-d", paste0("data/", x)))
  })

# Generate targets file
# initial_target_file.csv is a copy-paste from the GSE webpage to LibreOffice Calc
# savec as a csv file.
targets <- read.csv2("data/initial_target_file.csv", header = FALSE, stringsAsFactors = FALSE)
# Remove trailing spaces in sample names
targets$V1 <- sub("[[:blank:]]", "", targets$V1)
# Add Condition column
targets$Condicion <- as.factor(sub("-[[:print:]]+", "", targets[,2]))
# Add Material column
targets$Material <- as.factor(sub("[[:graph:]]+[[:blank:]]", "", targets[,2]))
# Add Group column
targets$Grupo <- as.factor(paste(targets$Condicion, targets$Material, sep="-"))
# Rearrange columns
targets <- targets[, c(1, 5, 3, 4, 2)]
# Change column names
colnames(targets)[c(1, 5)] <- c("Archivo", "Abreviado")
# Write final targets file
write.csv2(targets, file = "intermediateResults/targets2.csv", row.names = FALSE)
```


```{r delete results files, eval= FALSE}
# Run this chunk ONLY if you want to re-do
# all the report FROM ZERO.
# Remember that the .RData files are there to
# avoid unnecesarily redoing long data processing.

# file.remove(c("./results/clasificacion-radiografias.html"))


```


```{r libraries, include=FALSE}
# Install packages
# Load packages
# ...

library(knitr)

```

Grupos experimentales (columna grupos)
Condición del sujeto (condición)
Material usado (material)
Número total de muestras:


```{r construct targets file, eval=FALSE}
# Read the CEL files
library('oligo')
celFiles <- list.celfiles("data", full.names=TRUE)
# Generate phenoData
library(Biobase)
my.targets <- read.AnnotatedDataFrame(file.path("intermediateResults", "targets2.csv"), header = TRUE, row.names=1, sep = ";")
```

```{r Expression Set with read.celfiles, eval=FALSE}
# Construct the ExpressionSet object
library(primeviewprobe)
library(oligoClasses)
rawData <- read.celfiles(celFiles, phenoData = my.targets, pkgname="primeviewcdf")
```

```{r construct ExpressionSet with GEOquery, eval=FALSE}
library(GEOquery)
GEOfile <- "intermediateResults/gse.RData"
if(file.exists(GEOfile)){
  load(GEOfile)
}else{
gse <- getGEO("data/GSE113834_series_matrix.txt.gz", GSEMatrix = TRUE, destdir="data", getGPL = TRUE)
# The value is a list of ExpressionSet objects
# (each GSM is one of those ExpressionSet objects)
save("gse", file="intermediateResults/gse.RData")
}
gse_expr <- unlist(gse[[1]])
```
Probemos otro método para construir el objeto ExpressionSet:
```{r ExpressionSet con affy}
library(affy)
rawData <- read.affybatch(filenames = celFiles,
                          phenoData = my.targets)
```



# Control de calidad de los datos en bruto
Con el control de calidad pretendemos averiguar si los datos en bruto tienen calidad suficiente para continuar con el análisis, antes de normalizarlos.

En esta ocasión usaremos el paquete de análisis ArrayQualityMetrics.

```{r control de calidad con ArrayQualityMetrics}
library(arrayQualityMetrics)
arrayQualityMetrics(gse_expr)
```

```{r}
graph_colours <- c(rep("red", 3), rep("blue", 3), rep("yellow",3),
                rep("green", 3))
```


## Gráficos de densidad

Los gráficos de densidad...

```{r grafico de densidad}

```


## Diagrama de cajas

El gráfico de diagrama de cajas nos permite comparar la distribución de la intensidad entre las diferentes muestras.

```{r boxplot}
boxplot(rawData,
        names=pData(rawData)$X.Abreviado,
        cex.axis=0.5, las=2, which="both",
        col = graph_colours,
        main="Distribución de valores de intensidad en bruto")
```

Podemos ver que ninguna de las muestras destaca entre el resto. Hay pequeñas variaciones, pero es una característica esperable cuando comparamos los datos de intensidad en bruto.

# Apéndice A: Reproducibilidad
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
sessionInfo() # For better reproducibility
```








