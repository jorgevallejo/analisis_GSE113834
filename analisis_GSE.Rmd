---
title: "Análisis GSE113834"
subtitle: "Análisis Datos Ómicos - PEC 1"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
      toc: true
      #pandoc_args: -V toc-title="Sumario"
# Next code for knitting both types of documents automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all",
  output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE)

# This is a try:
knitr::opts_knit$set(stop_on_error = 2L)
# See ?evaluate::evaluate
# What I am trying to do is to make knitr stop
# when an error is found instead of running the
# complete script.
```

```{r estructura de directorios}
# Directory for raw data
if (!(dir.exists("data"))){
dir.create("data")
}
# Directory for results
if (!(dir.exists("results"))){
  dir.create("results")
}
# Directory for processed data
if (!(dir.exists("intermediateResults"))){
  dir.create("intermediateResults")
}
```

```{r prepare data, eval=FALSE}
GSE_address <- "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE113834"
data_origin <- "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE113834&format=file"
gpl_origin <- "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?mode=raw&is_datatable=true&acc=GPL15207&id=17536&db=GeoDb_blob169"

# De-compress files
cel_tar <- "data/GSE113834_RAW.tar"
untar(cel_tar, exdir = "data")
file.remove(cel_tar)
zip_files <- dir("data")
sapply(zip_files, function(x){
  system2("gunzip",
          args = c("-d", paste0("data/", x)))
  })

# Generate targets file
# initial_target_file.csv is a copy-paste of the samples/group table
# from the GSE webpage to LibreOffice Calc and saved as a csv file.
targets <- read.csv2("data/initial_target_file.csv", header = FALSE, stringsAsFactors = FALSE)
# Remove trailing spaces in sample names
targets$V1 <- sub("[[:blank:]]", "", targets$V1)
# Add Condition column
targets$Condicion <- as.factor(sub("-[[:print:]]+", "", targets[,2]))
# Add Material column
targets$Material <- as.factor(sub("[[:graph:]]+[[:blank:]]", "", targets[,2]))
# Add Group column
targets$Grupo <- as.factor(paste(targets$Condicion, targets$Material, sep="-"))
# Rearrange columns
targets <- targets[, c(1, 5, 3, 4, 2)]
# Change column names
colnames(targets)[c(1, 5)] <- c("Archivo", "Abreviado")
# Write final targets file
write.csv2(targets, file = "intermediateResults/targets2.csv", row.names = FALSE)
```


```{r delete results files, eval= FALSE}
# Run this chunk ONLY if you want to re-do
# all the report FROM ZERO.
# Remember that the .RData files are there to
# avoid unnecesarily redoing long data processing.

file.remove(c("./intermediateResults/dist_matrix.RData",
              "./intermediateResults/gse.RData",
              "./intermediateResults/Pset.RData",
              "./intermediateResults/targets2.csv"))


```


```{r libraries, include=FALSE}
# Install packages
# Load packages
# ...

library(knitr)

```

Grupos experimentales (columna grupos)
Condición del sujeto (condición)
Material usado (material)
Número total de muestras:


```{r construct targets file, eval=FALSE}
# Read the CEL files
library('oligo')
celFiles <- list.celfiles("data", full.names=TRUE)
# Generate phenoData
library(Biobase)
my.targets <- read.AnnotatedDataFrame(file.path("intermediateResults", "targets2.csv"), header = TRUE, row.names=1, sep = ";")
```

```{r Expression Set with read.celfiles, eval=FALSE}
# Construct the ExpressionSet object
library(primeviewprobe)
library(oligoClasses)
rawData <- read.celfiles(celFiles, phenoData = my.targets, pkgname="primeviewcdf")
```

```{r construct ExpressionSet with GEOquery, eval=FALSE}
library(GEOquery)
GEOfile <- "intermediateResults/gse.RData"
if(file.exists(GEOfile)){
  load(GEOfile)
}else{
gse <- getGEO("data/GSE113834_series_matrix.txt.gz", GSEMatrix = TRUE, destdir="data", getGPL = TRUE)
# The value is a list of ExpressionSet objects
# (each GSM is one of those ExpressionSet objects)
save("gse", file="intermediateResults/gse.RData")
}
gse_expr <- unlist(gse[[1]])
```
```{r}
gse <- getGEO("GSE113834", GSEMatrix = TRUE, destdir = "data", getGPL = TRUE)
```


Probemos otro método para construir el objeto ExpressionSet:
```{r ExpressionSet con affy}
library(affy)
rawData <- read.affybatch(filenames = celFiles,
                          phenoData = my.targets)
```



# Control de calidad de los datos en bruto
Con el control de calidad pretendemos averiguar si los datos en bruto tienen calidad suficiente para continuar con el análisis, antes de normalizarlos.

En esta ocasión usaremos el paquete de análisis ArrayQualityMetrics.

```{r control de calidad con ArrayQualityMetrics, eval=FALSE}
library(arrayQualityMetrics)
arrayQualityMetrics(rawData)
```

```{r re-used variables}
array_labels <- noquote(pData(rawData)$X.Abreviado.)
graph_colours <- rainbow(length(array_labels))
```


## Gráficos de densidad

Los gráficos de densidad nos informan acerca de la forma y posición de las señales sin normalizar.

```{r grafico de densidad}
hist(rawData, col = graph_colours,
     main="Densidad de la señal en bruto",
     ylab="Densidad", xlab= "log Intensidad")

legend(x=11.9, y=0.31, legend=array_labels, 
       fill=graph_colours, ncol=2, bty="n", cex=0.5)
```

Este caso vemos que la curva de densidad es similar en todas las muestras, sin mostrar grandes diferencias.

## Diagrama de cajas

El gráfico de diagrama de cajas nos permite comparar la distribución de la intensidad entre las diferentes muestras.

```{r boxplot}
boxplot(rawData,
        names=array_labels,
        cex.axis=0.5, las=2, which="both",
        col = graph_colours,
        main="Distribución de valores de intensidad en bruto")
```

Podemos ver que ninguna de las muestras destaca entre el resto. Hay pequeñas variaciones, pero es una característica esperable cuando comparamos los datos de intensidad en bruto.

## Dendrograma del clúster jerárquico

El dendrograma nos ayuda a representar cómo se agrupan las muestras, y da pistas acerca de cuál es el factor experimental que determina las diferencias entre muestras. Aquellas muestras con datos más similares aparecerán agrupadas.

```{r dendrograma, fig.height=5, fig.width=8}
# Calcular matriz de distancias
if(file.exists("intermediateResults/dist_matrix.RData")){
  load("intermediateResults/dist_matrix.RData")
  }else{
    dist_matrix <- dist(t(exprs(rawData)))
    save(dist_matrix, file = "intermediateResults/dist_matrix.RData")
  }
# Cambia el atributo 'Labels' con los nombres abreviados de las muestras.
attr(dist_matrix, "Labels")<- array_labels

hier_clust <- hclust(dist_matrix, "average")

plot(hier_clust, main="Dendrograma de datos muestrales en bruto",
     hang = -1, cex = 0.66, xlab= "Muestras", sub="", ylab = "", yaxt="n")
```

En este caso y a primera vista no parece haber un factor claro que haga que unas muestras están más cercanas entre sí que otras. Quizá el material (input/wash/eluted) en primer lugar, y el grupo (ctrl/asd) en segundo lugar; pero no es definitivo.

## Componentes principales

El análisis de componentes principales nos puede servir para detectar si las muestras se agrupan con otras muestras procedentes del mismo grupo o si no hay correspondencia entre muestras del mismo grupo.

```{r funcion plotPCA3}

# Función para visualización de componentes principales
# Código adaptado de Statistical Analysis of Microarray data (adapted for teaching purposes) Based on Gonzalo, Ricardo and Sanchez-Pla, Alex (2019)

 library(ggplot2)
 library(ggrepel)
 plotPCA3 <- function (datos, labels, factor, title, scale,colores, size = 1.5, glineas = 0.25) {
   data <- prcomp(t(datos),scale=scale)
   # plot adjustments
   dataDf <- data.frame(data$x)
   Group <- factor
   loads <- round(data$sdev^2/sum(data$sdev^2)*100,1)
   # main plot
   p1 <- ggplot(dataDf,aes(x=PC1, y=PC2)) +
     theme_classic() +
     geom_hline(yintercept = 0, color = "gray70") +
     geom_vline(xintercept = 0, color = "gray70") +
     geom_point(aes(color = Group), alpha = 0.55, size = 3) +
     coord_cartesian(xlim = c(min(data$x[,1])-5,max(data$x[,1])+5)) +
     scale_fill_discrete(name = "Grupo")
   # avoiding labels superposition
   p1 + geom_text_repel(aes(y = PC2 + 0.25, label = labels),segment.size = 0.25, size = size) + 
     labs(x = c(paste("PC1",loads[1],"%")),y=c(paste("PC2",loads[2],"%"))) +  
     ggtitle(paste("Análisis de componentes principales para: ",title,sep=" "))+ 
     theme(plot.title = element_text(hjust = 0.5)) +
     scale_color_manual(values=colores)
 }
```

```{r componentes ppales}
plotPCA3(exprs(rawData), labels = array_labels,
         factor = pData(rawData)$X.Grupo, title="Datos brutos",
         scale = FALSE, size = 3, colores = rainbow(6))
```

De forma similar a lo que veíamos en el dendrograma, las diferencias más importantes entre las muestras parecen deberse al material antes que al grupo.

La componente más importante explica el 67.7% de la variabilidad total de las muestras, y parece deberse principalmente al material; las muestras "wash" se agrupan más a la izquierda, compartiendo la zona central con las muestras "input", y las muestras "eluted" agrupadas hacia la derecha del gráfico.

La muestra "CTRL-1 INPUT" aparece alejada, no sólo de las otras muestras del grupo CTRL-INPUT, sino de todo el resto de muestras. Esto por sí sólo no significa que la muestra sea defectuosa, pero sí que deberíamos fijarnos en ella y comprobar qué resultados obtiene en el resto de gráficos.

## Imagen del array

Examinar la imagen del array nos permite hacer una evaluación de calidad a nivel "macro". Nos permite hacer una estimación a ojo de características como del balance del color, la uniformidad en la hibridación y en los spots, de si el background es mayor de lo normal y de la existencia de artefactos como el polvo o pequeñas marcas (rasguños).


```{r array image, fig.height=32, fig.width=12}
#pseudo image of the weights for the first arrays in the dataset
par(mfrow=c(9,3))
for (num in 1:length(array_labels)){
  image(rawData[, num], main = array_labels[num])
}
```

Todas las imágenes tienen una estructura en el centro que no he sabido averiguar si corresponde a los datos originales o si la he introducido y inadvertidamente mientras manipulaba los datos.

A simple vista no se observa ningún gran defecto como roturas, burbujas o manchas. Si que parece a simple vista que las imágenes de material "INPUT" son más oscuras que el resto.

# Normalización de los datos

Antes de empezar el análisis de expresión es necesario procesar los datos brutos de forma que los datos de las diferentes muestras (micorarrays) sean comparables. El proceso de normalización intenta asegurarse de que las diferencias de intensidad reflejen la expresión diferencial de los genes, eliminando sesgos producidos por razones técnicas.

El método de normalización que usaremos en este análisis es el RMA (_robust multi-array
average_), que es uno de los más usados en el ecosistema de Bioconductor.

```{r normalizacion RMA}
# First checks if the expressionset has been already calculated and saved
eset_rma_file <- file.path("intermediateResults", "eset_rma.RData")

if(file.exists(eset_rma_file)){
  load(eset_rma_file)
}else{
  eset_rma <- affy::rma(rawData)
  save(eset_rma, file = eset_rma_file)
}
```

# Control de calidad sobre datos normalizados

Después de la normalización volvemos a realizar un control de calidad, para comprobar que el resultado de la normalización ha producido el efecto esperado en la distribución de los datos.

## Diagrama de cajas

Con gráfico de diagrama de cajas volvemos a comparar la distribución de la intensidad entre las diferentes muestras.

```{r boxplot datos normalizados}
boxplot(eset_rma,
        names=array_labels,
        cex.axis=0.5, las=2,
        col = graph_colours,
        main="Distribución de valores de intensidad normalizados (RMA)")
```

Si lo comparamos con el gráfico de antes de normalizar, en éste la distribución de intensidades es mucho más uniforme entre muestras.

## Componentes principales

El análisis de componentes principales nos puede servir para detectar si las muestras se agrupan con otras muestras procedentes del mismo grupo o si no hay correspondencia entre muestras del mismo grupo.

```{r componentes ppales datos normalizados}
plotPCA3(exprs(eset_rma), labels = array_labels,
         factor = pData(eset_rma)$X.Grupo, title="Datos normalizados",
         scale = FALSE, size = 3, colores = rainbow(6))
```

Ahora el primer componente es responsable del 37% de la variabilidad total. Casi la mitad de lo que ocurría al utilizar los datos brutos. Las muestras se siguen separando según material, con "INPUT" en el centro, igual que antes; pero en esta ocasión "ELUTED" a la izquierda y "WASH" a la derecha. No sé si este cambio de orientación tiene algún significado o si es producido por el cálculo matricial.

La variabilidad explicada por la componente secundaria es el 16%, y también parece depender del material; separando claramente "INPUT" de los otros dos materiales ("ELUTED" y "WASH"). El grupo sin embargo - "CTRL" frente a "ASD" -, no parece tener una gran influencia en la variabilidad.

Un cambio notable en el diagrama de componentes es prinpales es la posición de la muestra "CTRL-1 INPUT", que ya no aparece separada del resto como sí ocurría al utilizar los datos brutos.

En conclusión, podríamos decir que la normalización de los datos ha producido el efecto esperado y no encontramos impedimento para proceder al análisis de los datos.

# Filtraje no específico

En una primera selección de genes, dejaremos fuera aquellos genes que varían poco entre condiciones, y aquellos para los que no disponemos de anotación.

```{r read GPL15207 table}
# This chunk reads the GPL15207 data from the file
# data/GPL15207-17536.txt
# Such file has been previously downloaded from the
# address stored in the variable gpl_origin

# Read the lines of the file
gpl_text <- readLines("data/GPL15207-17536.txt")
# Identify the line just before the headers line
# This will be used as the starting point for read.table()
start_row <- grep("#SPOT_ID =", gpl_text)

gpl_table_file <- "intermediateResults/gpl_table.RData"

if(file.exists(gpl_table_file)){
  load(gpl_table_file)
}else{
  gpl_table <- read.table("data/GPL15207-17536.txt", sep = "\t",
                        skip = start_row,
                        # In the GPL table NA values are codified as "---"
                        na.strings = "---",
                        colClasses = "character", 
                        stringsAsFactors = FALSE,
                        header = TRUE, fill = TRUE,
                        quote="", comment.char = "")
  save(gpl_table, file = gpl_table_file)
}

# Create table with probeID and EntrezID
gpl_entrezid <- gpl_table[,c("ID", "Entrez.Gene")]
```

```{r filtraje a mano}
# Make a dataframe combining probeID, IQR, and EntrezID
IQR_set <- apply(exprs(eset_rma), 1, IQR)
IQR_dataframe <- as.data.frame(IQR_set)
colnames(IQR_dataframe) <- c("IQR")
IQR_combined <- merge(IQR_dataframe, gpl_entrezid,
                      by.x = 0, by.y = "ID")

# Filter out Affymetrix QC probes
QCprobes <- grep("^AFF", IQR_combined$Row.names)
IQR_noprobes <- IQR_combined[-QCprobes, ]
# Filter out probes without Entrez ID
    # Vector with the indexes of NA in column Entrez.Gene
no_entrez <- which(is.na(IQR_noprobes$Entrez.Gene) == TRUE)
IQR_no_entrez <- IQR_noprobes[-no_entrez, ]
# Nevertheless, I know that there are probes that map to
# two or more different EntrezIDs. I don't know how to
# handle those cases.
```

Affymetrix Quality Control probes: `r length(QCprobes)`
Probes without Entrez ID: `r length(no_entrez)`

```{r sondas para el mismo codigo Entrez}
# Order files (descendant) for entrezId, then for IQR
ordered_IQR <- IQR_no_entrez[ order(IQR_no_entrez$Entrez.Gene, 
                                   -IQR_no_entrez$IQR), ]
# Make logical vector of duplicates
dup_entrez <- duplicated(ordered_IQR$Entrez.Gene)
dup_rows <- which(dup_entrez == TRUE)
filtered_probes <- ordered_IQR[-dup_rows, ]
```

Probes filtered for duplication: `r sum(dup_entrez)`

```{r filtraje no especifico, eval=FALSE}
library('genefilter')
library('primeviewprobe')
# annotation(eset_rma) <- "primeviewprobe"
filtered <- nsFilter(eset_rma, require.entrez = FALSE,
                     remove.dupEntrez = FALSE, var.func = IQR,
                     var.cutoff = 0.5, var.filter = TRUE,
                     filterByQuantile = TRUE, feature.exclude = "^AFFX")
# Elimina las sondas cuyo rango interquantil (IQR) sea menor a la mediana
# de todos los IQR.

# Al no tener un paquete de anotaciones, no hemos realizado el filtraje de
# duplicados ni el filtraje de sondas sin código Entrez.
```

Número inicial de sondas: `r format(nrow(exprs(eset_rma)), big.mark= " ")`

Sondas excluidas por baja variabilidad: `r format(filtered$filter.log$numLowVar), big.mark= " "`
Sondas excluidas por ser controles de calidad del chip: `r format(filtered$filter.log$feature.exclude), big.mark= " "`

Número de sondas para siguientes análisis: `r format(nrow(exprs(filtered$eset)), big.mark= " ")`

# Apéndice A: Reproducibilidad
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
sessionInfo() # For better reproducibility
```








